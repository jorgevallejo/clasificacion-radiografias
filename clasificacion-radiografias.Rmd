---
title: "Clasificación de imagenes de radiografias de tórax entre normales y con derrame"
subtitle: "Machine Learning - PEC 1"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document: 
      toc: true
      toc_float: true
  pdf_document:
      toc: true
# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all") })

---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = TRUE)

# This is a try:
knitr::opts_knit$set(stop_on_error = 2L)
# See ?evaluate::evaluate
# What I am trying to do is to make knitr stop
# when an error is found instead of running the
# complete script.
```

```{r libraries, include=FALSE}
# Install packages
# Load packages
# ...

library(knitr)
```

# Índice

# Algoritmo k-NN

El algoritmo de los k vecinos más próximos (_k-nearest neighbours_) es un algoritmo de aprendizaje automático (_machine learning_) que se utiliza para clasificar observaciones, según si sus características las hacen más parecidas a uno u otro grupo ya establecidos.  

En una primera fase de 'entrenamiento', una colección de observaciones ya clasificadas se distribuyen en un espacio _n_-dimensional. Cada dimensión corresponde a una de las variables medidas en las observaciones. Las nuevas observaciones, las cuales queremos clasificar, se distribuyen a su vez en ese espacio _n_-dimensional; y se clasifican dentro de los grupos a los que pertenezcan aquellas otras observaciones, ya clasificadas, de las que más cerca se encuentren. El número de observaciones conocidas que tenemos en cuenta para clasificar las observaciones nuevas, es ése número _k_.


## Fortalezas y debilidades del algoritmo

```{r fortalezas debilidades, echo=FALSE, results='asis'}
fort_deb <- matrix(c("*Simple y efectivo",
              "* No hace asunciones acerca de la distribución subyacente de los datos",
              "* Fase de entrenamiento rápida",
              " ",
              "* No produce un modelo, limitando la habilidad para entender cómo las características se relacionan con la clasificación",
              "* Requiere seleccionar una _k_ adecuada",
              "* Fase de clasificación lenta",
              "* Se requiere procesado adicional para características nominales y datos incompletos"),
              ncol=2)
col_names <- c("Fortalezas", "Debilidades")
kable(fort_deb, col.names = col_names)
```


# Pre-procesado de datos

Las imágenes a clasificar deberán estar en una carpeta llamada "dataset", en el mismo directorio que el código que vamos a correr.
```{r set directories structure}
dir.create("./results", showWarnings = FALSE)

if (! dir.exists("./dataset")) {
  stop("El directorio ./dataset no existe")
}

# DONE Si datasets existe
#    si contiene datos
#        Continúa con el script
#    else: Aviso (La carpeta datasets no contiene datos)
# DONE Else: la carpeta datasets no existe
```

```{r function image to vector}
library('OpenImageR')

image_tovector <- function(x){
# Create filepath
filepath <- paste("./dataset", sep='/',
                  paste(as.vector(x), collapse = '/'))
#print(filepath)
# Read image
image <- readImage(filepath)
# Convert to greyscale
image_grey <- rgb_2gray(image)
# Resize to 64x64
image_resized <- resizeImage(image_grey, 64, 64)
# Transform from matrix to vector
return(as.vector(image_resized))
}

## TODO ## Incluir en el informe ejemplos de imagenes antes y después del preprocesado (función imageShow()).

```

```{r extract directories and filenames}
directories <- list.dirs("./dataset", full.names = FALSE, recursive = FALSE)
filenames <- as.data.frame(
  sapply(directories,
                    function (x){return(
                      list.files(paste0("./dataset/", x)))}))

# From wide to long format
filenames <- reshape(filenames,
                      direction="long",
                      varying = c("effusion", "normal"),
                      v.names="Filename",
                      timevar="cat",
                      times = c("effusion", "normal")
                      )
row.names(filenames) <- NULL
filenames$id <- NULL
#filenames$Condition <- as.factor(filenames$Condition)
filenames$Filename <- as.character(filenames$Filename)
```

```{r create dataframe of vectorized images}

#Check if the file already exists
if(file.exists("image_vectors.RData")){
  load("image_vectors.RData")
}else{
# Matrix of vectorized images
image_vectors <- apply(filenames, 1, image_tovector)
save(image_vectors, file = "image_vectors.RData")
}
# This if-else block is to avoid re-calculating 
# the object every time I want to try the code.
# I have just have care to remove the .RData file
# if I want to re-calculate it.

## TODO Keep the file names as col names

# Transpose to have images as observations
image_vectors <- as.data.frame(t(image_vectors))
```

```{r test images in rows, eval=FALSE}
## How to check if each row if really an x-ray image:
test_row <- function(x){
# Extract one row of the dataframe and store as a numeric vector
 test <- as.numeric(image_vectors[x,])
# Transform vector into matrix
 test <- matrix(test, ncol=64)
# Check if you obtain an x-ray image
 imageShow(test)
}
```

```{r final dataframe with filenames and diagnostic}
image_vectors <- cbind(filenames, image_vectors)
# Change cat variable to factors
image_vectors$cat <- as.factor(image_vectors$cat)
levels(image_vectors$cat) <- c("e", "n")
```

```{r write the dataframe into a csv file}
if( ! file.exists("./results/RX_Torax_4097.csv")){
  write.csv2(image_vectors,
           file="./results/RX_Torax_4097.csv",
           row.names = FALSE)
}

# Structured in that way to avoid writing the file
# each time that I want to test the script,
# especially if I just want to test knitting
```

### Lectura de datos
```{r lectura del fichero csv}
image_vectors <- read.csv2("./results/RX_Torax_4097.csv")
```


### Estructura de los datos
```{r examine data structure}
observaciones <- nrow(image_vectors)
variables <- ncol(image_vectors)-2
 
```

El set de datos examinado está compuesto por `r observaciones` observaciones, de las cuales se han tomado `r variables` variables, y están divididas en `r length(directories)` clases (`r directories`) that are codified as `r levels(image_vectors$cat)`.

La distribución de cada clase es la siguiente:

```{r}
kable(table(image_vectors$cat),
      col.names = c("Clase", "Frecuencia"),
      align = c('r','l'))
```

### Histograma de medias

```{r calcula la media de cada variable}
image_vectors_normal <- image_vectors[image_vectors$cat == 'n',]
image_vectors_effusion <- image_vectors[image_vectors$cat == 'e',]

media_normal <- apply(image_vectors_normal[,3:ncol(image_vectors_normal)], 2, mean)
media_effusion <- apply(image_vectors_effusion[,3:ncol(image_vectors_effusion)], 2, mean)
```

```{r calcula la desviación típica de cada variable}
sd_normal <- apply(image_vectors_normal[,3:ncol(image_vectors_normal)], 2, sd)
sd_effusion <- apply(image_vectors_effusion[,3:ncol(image_vectors_effusion)], 2, sd)
```

```{r max histogramas media, include=FALSE}
# Para calcular los rangos de las frecuencias
hmn <- hist(media_normal)
hme <- hist(media_effusion)
max_y <- ceiling(max(c(hmn$counts, hme$counts))/100)*100
```

```{r histogramas media}
par(mfrow= c(1,2))
hist(media_normal,
     main="Valor medio de las variables\nClase normal",
     ylab = "Frecuencia",
     xlab = "Media",
     xlim = c(0,1),
     ylim = c(0, max_y))

hist(media_effusion,
     main="Valor medio de las variables\nClase effusion",
     ylab = "Frecuencia",
     xlab = "Media",
     xlim = c(0,1),
     ylim = c(0, max_y))
```

Los valores medios de las variables en la clase "normal" parecen estar más concentrados en el centro de la distribución, mientras que en la clase "effusion" la distribución es más achatada. Esto podría significar que las imágenes de la clase "effusion" presentan áreas más claras y más oscuras que las imágenes de la clase "normal".

```{r max histogramas desviación típica, include=FALSE}
# Para calcular los rangos de las frecuencias
hsn <- hist(sd_normal)
hse <- hist(sd_effusion)
max_ye <- ceiling(max(c(hsn$counts, hse$counts))/100)*100
max_xe <- max(c(sd_effusion, sd_normal))
```

```{r histogramas desviación típica}
par(mfrow= c(1,2))
hist(sd_normal,
     main="Desviación típica de las variables\nClase normal",
     ylab = "Frecuencia",
     xlab = "Media",
     xlim = c(0,max_xe),
     ylim = c(0, max_ye))

hist(sd_effusion,
     main="Desviación típica de las variables\nClase effusion",
     ylab = "Frecuencia",
     xlab = "Desviación típica",
     xlim = c(0,max_xe),
     ylim = c(0, max_ye))
```

Por la forma de los histogramas, y los rangos de valores en los que se mueven, parece que las variales en las observaciones de clase "effusion" presentan valores de desviación típica mayores que las variables en la clase "normal".


## Contraste de valores medios (t-test)

```{r test t}
# Código adaptado de
# https://stackoverflow.com/questions/13790611/apply-t-test-on-many-columns-in-a-dataframe-split-by-factor
variables_t_test <- t(sapply(image_vectors[c(-1,-2)], function(x)
  unlist(t.test(x~image_vectors$cat)[c("estimate", "p.value")])))
```

```{r ajustar p-valores por correccion de Benjamini & Hochberg (BH)}
variables_t_test_adjusted <- as.data.frame(variables_t_test)
variables_t_test_adjusted[,3] <- p.adjust(variables_t_test_adjusted[,3])
# Ordenar los valores de menor a mayor
ordered_p_values <- variables_t_test_adjusted[order(variables_t_test[,3]),]
# Añadir columna con diferencia de medias
ordered_p_values[, "diferencia"] <- ordered_p_values[,1] - ordered_p_values[,2]
# Preparar para mostrar como tabla
library(xtable)
xtable(ordered_p_values[1:25,-c(1,2)],
       caption = "Tabla con los 25 descriptores de menor p-valor",
       digits = 4,
       display=c("s", "e", "fg"))
```

Me llama la atención que en estos descriptores estadísticamente más significativos, la diferencia entre las medias del grupo "derrame"" y del grupo "normal" es de alrededor del 20%.


## TODO: Normalizar los p-valores ajustados, asociarlos a una escala de color y reconstruir la imagen para saber qué zonas de la imagen son más informativas.


## Implementación del algoritmo knn

Dividimos el set de datos, al azar, en un set de entrenamiento (67% de las observaciones) y un set de prueba (33% de los datos).

```{r separa sets entrenamiento y prueba}
set.seed(123)
# Reordered row numbers
observaciones <- nrow(image_vectors)
shuffled_rows <- sample(observaciones)
training_rows <- shuffled_rows[1:(observaciones*0.67)]
test_rows <- shuffled_rows[((observaciones*0.67)+1):observaciones]
# Remember to use only numeric variables
image_vectors_training <- image_vectors[training_rows, 3:ncol(image_vectors)]
image_vectors_test <- image_vectors[test_rows, 3:ncol(image_vectors)]

# Category labels
image_vectors_train_labels <- image_vectors_training[, 1]
image_vectors_test_labels <- image_vectors_test[, 1]
```

## Evalúa diferentes valores de k
```{r classify the test data and evaluate different k values}
library('class')
library('gmodels')

k <- c(3, 5, 7, 11, 23, 45, 67)

evaluator <- function (x){
  image_vectors_test_pred <- knn(train = image_vectors_training,
                               test = image_vectors_test,
                               cl = image_vectors_train_labels, 
                               k=x)
  Results_table <- prop.table(
    table(image_vectors_test_labels,
          image_vectors_test_pred))
  return(c(x, Results_table[3], Results_table[2]))
}

#Check if the file already exists
if(file.exists("./results/evaluated_k.RData")){
  load("./results/evaluated_k.RData")
}else{
# Evaluate the different k values
  evaluated_k <- sapply(k, evaluator)
  save(evaluated_k, file="./results/evaluated_k.RData")
}
# This if-else block is to avoid re-calculating 
# the object every time I want to try the code.
# I have just have care to remove the .RData file
# if I want to re-calculate it.


# Format results as a data frame
dtevaluated_k <- as.data.frame(t(evaluated_k))
# Add column for total errors of classifying
dtevaluated_k[,4] <- (dtevaluated_k[,2] + dtevaluated_k[,3])
# Add column names
colnames(dtevaluated_k) <- c("k","False Negatives", "False Positives", "Total Error")
# Format as percentages
dtevaluated_k[,2:4] <- round(dtevaluated_k[,2:4], 3)*100
dtevaluated_k[,2:4] <- mapply(paste0, dtevaluated_k[,2:4], "%")

# Print table
knitr::kable(dtevaluated_k,
             align = c("c","c","c","c"))
```














